{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGoul82fp8nN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import*\n",
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A24qqpBEp8nS"
   },
   "outputs": [],
   "source": [
    "#initialisation\n",
    "\n",
    "n_most_similar = 1\n",
    "n_features_title = 25\n",
    "n_features_content = 50\n",
    "n_features_tags = 25\n",
    "n_features_total = 30\n",
    "\n",
    "\n",
    "df = None #dataframe\n",
    "df_article_vectors = None #vectorized articles\n",
    "similarity_score_dict = {} #similarity score dictionary for articles\n",
    "X = None\n",
    "X_title = None  #vectorized title\n",
    "X_content = None  #vectorized content\n",
    "X_tags = None #vectorized tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QiYJ2Gzkp8nU"
   },
   "source": [
    "# DATA LOADING + CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1005,
     "status": "error",
     "timestamp": 1541842168538,
     "user": {
      "displayName": "Indraneel Amara",
      "photoUrl": "",
      "userId": "08000725539825589482"
     },
     "user_tz": -330
    },
    "id": "BtlnFCcap8nV",
    "outputId": "31c6edf6-b8b3-4d41-8ee1-7ce0264a8789",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content_text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Automating routine with a hackathon</td>\n",
       "      <td>In today's hectic world, it's valuable to look...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making Work A Work-Out: AR At The Office</td>\n",
       "      <td>This post concerns Greenhouse Group Labs, an i...</td>\n",
       "      <td>['Augmented Reality', 'Health', 'Work', 'Weara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creating a lightweight game using PixiJs - part 1</td>\n",
       "      <td>We live in a world in which advertisement is m...</td>\n",
       "      <td>['JavaScript', 'PIXI', 'PixiJs', 'canvas', 'ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can AR reach Generation Z where normal adverti...</td>\n",
       "      <td>With an average attention span of 12 seconds a...</td>\n",
       "      <td>['Snapchat', 'Facebook', 'Augmented Reality', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Rise &amp; All of Social AR</td>\n",
       "      <td>In the new age of AR, they way we connect with...</td>\n",
       "      <td>['Facebook', 'Augmented Reality', 'Social adve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                Automating routine with a hackathon   \n",
       "1           Making Work A Work-Out: AR At The Office   \n",
       "2  Creating a lightweight game using PixiJs - part 1   \n",
       "3  Can AR reach Generation Z where normal adverti...   \n",
       "4                        The Rise & All of Social AR   \n",
       "\n",
       "                                        content_text  \\\n",
       "0  In today's hectic world, it's valuable to look...   \n",
       "1  This post concerns Greenhouse Group Labs, an i...   \n",
       "2  We live in a world in which advertisement is m...   \n",
       "3  With an average attention span of 12 seconds a...   \n",
       "4  In the new age of AR, they way we connect with...   \n",
       "\n",
       "                                                tags  \n",
       "0                                                 []  \n",
       "1  ['Augmented Reality', 'Health', 'Work', 'Weara...  \n",
       "2  ['JavaScript', 'PIXI', 'PixiJs', 'canvas', 'ga...  \n",
       "3  ['Snapchat', 'Facebook', 'Augmented Reality', ...  \n",
       "4  ['Facebook', 'Augmented Reality', 'Social adve...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(r\"C:\\Users\\DELL\\Desktop\\sem_5_assignments\\da\\Project\\articles123.csv\", encoding='utf-8') # Load articles in a DataFrame\n",
    "df = df[['title', 'content_text', 'tags']]  # Slice to remove redundant columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5JqBRsFp8nb",
    "outputId": "8a309001-1209-405f-ce48-67c89afe14a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             none\n",
       "1                augmented reality\n",
       "2                       javascript\n",
       "3                         snapchat\n",
       "4                         facebook\n",
       "5                augmented reality\n",
       "6                     data science\n",
       "7                 google analytics\n",
       "8                             tech\n",
       "9               google tag manager\n",
       "10                       analytics\n",
       "11                       analytics\n",
       "12                       analytics\n",
       "13     consumer friendly marketing\n",
       "14                       analytics\n",
       "15                            code\n",
       "16                       analytics\n",
       "17                    data science\n",
       "18                         adwords\n",
       "19                            none\n",
       "20                             cro\n",
       "21                            none\n",
       "22                            code\n",
       "23                            none\n",
       "24                       analytics\n",
       "25                            code\n",
       "26                            none\n",
       "27                       analytics\n",
       "28                            none\n",
       "29                       analytics\n",
       "                  ...             \n",
       "156                           code\n",
       "157                         events\n",
       "158                         mobile\n",
       "159                      analytics\n",
       "160                           code\n",
       "161                           code\n",
       "162                      marketing\n",
       "163                           code\n",
       "164                           code\n",
       "165                           code\n",
       "166                           code\n",
       "167                      marketing\n",
       "168                   data science\n",
       "169                           code\n",
       "170                      marketing\n",
       "171                      analytics\n",
       "172                           code\n",
       "173                   data science\n",
       "174                       ghostery\n",
       "175                     optimizely\n",
       "176                            cro\n",
       "177                   data science\n",
       "178                      angularjs\n",
       "179                            cro\n",
       "180               google analytics\n",
       "181                       thoughts\n",
       "182                        testing\n",
       "183                      analytics\n",
       "184                          html5\n",
       "185                   introduction\n",
       "Name: first_tag, Length: 186, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning tags to each article\n",
    "temp = df['tags']      \n",
    "temp = temp.str.lower()\n",
    "temp = temp.str.split(\",\", n = 1, expand = True)\n",
    "temp = temp[0]\n",
    "temp = temp.str.replace(\"[\",\"\")\n",
    "temp = temp.str.replace(\"]\",\"\")\n",
    "temp = temp.str.replace(\"'\",\"\")\n",
    "df['first_tag'] = temp\n",
    "df\n",
    "\n",
    "for i in range(0, len(df[\"first_tag\"])):\n",
    "    if df[\"first_tag\"][i] == '':\n",
    "        df[\"first_tag\"][i] = 'none'\n",
    "df[\"first_tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7n4rYibHp8nf",
    "outputId": "66f7f8de-0258-41b5-d07f-f6350d019cb5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content_text</th>\n",
       "      <th>tags</th>\n",
       "      <th>first_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>How close is Facebook to becoming The Circle?</td>\n",
       "      <td>Sometimes the future is coming at you at a fas...</td>\n",
       "      <td>['Facebook', 'f8', 'the circle', 'video stream...</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Rise &amp; All of Social AR</td>\n",
       "      <td>In the new age of AR, they way we connect with...</td>\n",
       "      <td>['Facebook', 'Augmented Reality', 'Social adve...</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>5 reasons why you need a JavaScript style guide</td>\n",
       "      <td>JavaScript style guides have been a hot topic ...</td>\n",
       "      <td>['Code']</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Working with Creative Macros in AppNexus hoste...</td>\n",
       "      <td>As a creative developer, one of the best featu...</td>\n",
       "      <td>['Code', 'appnexus', 'Adtech']</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Passing query string parameters to a creative ...</td>\n",
       "      <td>After years of experience in performance marke...</td>\n",
       "      <td>['Code', 'appnexus']</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "97       How close is Facebook to becoming The Circle?   \n",
       "4                          The Rise & All of Social AR   \n",
       "161    5 reasons why you need a JavaScript style guide   \n",
       "25   Working with Creative Macros in AppNexus hoste...   \n",
       "108  Passing query string parameters to a creative ...   \n",
       "\n",
       "                                          content_text  \\\n",
       "97   Sometimes the future is coming at you at a fas...   \n",
       "4    In the new age of AR, they way we connect with...   \n",
       "161  JavaScript style guides have been a hot topic ...   \n",
       "25   As a creative developer, one of the best featu...   \n",
       "108  After years of experience in performance marke...   \n",
       "\n",
       "                                                  tags first_tag  \n",
       "97   ['Facebook', 'f8', 'the circle', 'video stream...  facebook  \n",
       "4    ['Facebook', 'Augmented Reality', 'Social adve...  facebook  \n",
       "161                                           ['Code']      code  \n",
       "25                      ['Code', 'appnexus', 'Adtech']      code  \n",
       "108                               ['Code', 'appnexus']      code  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fyP4qD5Tp8ni"
   },
   "source": [
    "# CONVERTING ARTICLES TO NUMERIC FORMAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6g2HRTdHp8nj"
   },
   "source": [
    "vectorize data\n",
    "\n",
    "Vectorize training data, i.e. perform a 3-gram feature extraction and selection method using FP, Chi or RP\n",
    "\n",
    "return: Result is a numeric and weighted feature vector notation for each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8eATWLpXp8nk"
   },
   "outputs": [],
   "source": [
    "def vectorize_articles():\n",
    "\n",
    "        # Vectorize article\n",
    "        vectorize_title()    # Add title as dummies\n",
    "        vectorize_content()  # Add content as dummies\n",
    "        vectorize_tags()     # Add title as dummies\n",
    "     # Concatenate all article vectors, i.e. title, content, tags and author\n",
    "        article_metrics = (X_title, X_content, X_tags)\n",
    "        global X\n",
    "        X = np.concatenate(article_metrics, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMOKi7yEp8nm"
   },
   "outputs": [],
   "source": [
    "# vectorizer function : uses the concept of BOW(bag of words) along with n-gram(to preserve some ordering) \n",
    "def get_vectorizer(ngram_range=(1, 3), min_df=2, max_df=1.0):\n",
    "    \n",
    "        vectorizer = CountVectorizer(ngram_range=ngram_range,\n",
    "                                     tokenizer=tokenize,\n",
    "                                     min_df=min_df,\n",
    "                                     max_df=max_df,\n",
    "                                     binary=True,\n",
    "                                     stop_words='english')\n",
    "        return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRO2vLmdp8nq"
   },
   "outputs": [],
   "source": [
    "# tokenization function to be passed as the tokenizer to the CountVectorizer function\n",
    "# removes white spaces, stop words and stems the document\n",
    "def tokenize(text):\n",
    "    tokens = nltk.WhitespaceTokenizer().tokenize(text)\n",
    "    tokens = list(set(re.sub(\"[^a-zA-Z\\']\", \"\", token) for token in tokens))\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    tokens = list(set(re.sub(\"[^a-zA-Z]\", \"\", token) for token in tokens))\n",
    "    stems = []\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    for token in tokens:\n",
    "        token = stemmer.stem(token)\n",
    "        if token != \"\":\n",
    "            stems.append(token)\n",
    "    return stems\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpGIkQkTp8ns"
   },
   "outputs": [],
   "source": [
    "# vectorize title\n",
    "def vectorize_title():\n",
    "    global X_title\n",
    "    vectorizer = get_vectorizer(ngram_range=(1, 2),min_df=2)\n",
    "    X_title = vectorizer.fit_transform(train['title'])\n",
    "    X_title = X_title.toarray()\n",
    "    X_title = np.array(X_title, dtype=float)\n",
    "    print(X_title[0])\n",
    "    X_title = reduce_dimensionality(X_title, n_features=n_features_title)\n",
    "    print(X_title[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QA9SwIk7p8nu"
   },
   "outputs": [],
   "source": [
    "# vectorize content\n",
    "def vectorize_content():\n",
    "    global X_content\n",
    "    vectorizer = get_vectorizer(ngram_range=(1, 1),min_df=4,max_df=0.3)\n",
    "    X_content = vectorizer.fit_transform(train['content_text'])\n",
    "    X_content = X_content.toarray()\n",
    "    X_content = np.array(X_content, dtype=float)\n",
    "    X_content = reduce_dimensionality(X_content, n_features=n_features_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_6YIyr8p8nw"
   },
   "outputs": [],
   "source": [
    "# vectorize tags\n",
    "def vectorize_tags():\n",
    "    global X_tags\n",
    "    n_tags = 0\n",
    "    df_tags = pd.DataFrame(index=train.index)\n",
    "    # df_tags\n",
    "    df_tags.columns\n",
    "    for index, row in train.iterrows():\n",
    "            if row['tags'] != '':\n",
    "                values = row['tags'].split(\", \")\n",
    "                for value in values:\n",
    "                    if value not in df_tags.columns:\n",
    "                        df_tags[value] = 0.0\n",
    "                        n_tags += 1\n",
    "                    df_tags.ix[index, value] = 1.0\n",
    "    X_tags = np.array(df_tags, dtype=float)\n",
    "    X_tags = reduce_dimensionality(X_tags, n_features=n_features_tags)\n",
    "    \n",
    "# df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNJnarScp8nz"
   },
   "outputs": [],
   "source": [
    "# Reduce the dimensionality of the vectorized articles.\n",
    "def reduce_dimensionality_articles():\n",
    "        X = reduce_dimensionality(X, n_features=n_features_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gn5qOHvIp8n2"
   },
   "outputs": [],
   "source": [
    "# Apply PCA or SVD to reduce dimension to n_features.\n",
    "def reduce_dimensionality(X, n_features):\n",
    "        # Initialize reduction method: PCA or SVD\n",
    "        # reducer = PCA(n_components=n_features)\n",
    "        reducer = TruncatedSVD(n_components=n_features)\n",
    "        # Fit and transform data to n_features-dimensional space\n",
    "        reducer.fit(X)\n",
    "        X = reducer.transform(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DFXvuFXDp8n4",
    "outputId": "a454547e-99c4-48b7-d5b9-6fb87a730936"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:286: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afterward', 'alon', 'alreadi', 'alway', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becom', 'besid', 'cri', 'describ', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'otherwis', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev'] not in stop_words.\n",
      "  sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 3.50458375e-02 -2.24550828e-04  8.62114923e-02 -3.28320622e-02\n",
      " -3.71204291e-02  1.55624189e-01 -8.61697392e-02  8.41137234e-02\n",
      "  1.48560501e-01  4.65414374e-01 -3.82754967e-01 -1.52997357e-01\n",
      " -6.49368939e-02 -1.24585916e-01 -1.50819912e-01 -2.28297290e-01\n",
      "  8.54045348e-02 -4.72329989e-02 -5.11525173e-02  5.05030907e-02\n",
      "  1.60780771e-01 -8.24162585e-02 -2.30324099e-01  1.56513956e-01\n",
      " -1.01600397e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:286: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afterward', 'alon', 'alreadi', 'alway', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becom', 'besid', 'cri', 'describ', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'otherwis', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev'] not in stop_words.\n",
      "  sorted(inconsistent))\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "vectorize_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bWoOpPEip8n_",
    "outputId": "5e399cf7-71c9-4a23-8840-09fffac11ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00150106  0.0048266   0.01548515 -0.002083    0.02106006  0.0333919\n",
      "  0.01166168 -0.01975575  0.06052524 -0.01855336 -0.00303903  0.01510054\n",
      "  0.03722839 -0.04005427  0.0088162   0.02470957  0.11653944 -0.16194471\n",
      " -0.0016171   0.10807749  0.16460744 -0.01204254  0.05417049  0.10052163\n",
      "  0.28695412]\n",
      "[ 0.10564164  0.06151793  0.55720656  0.1857024   1.22812022 -0.20766614\n",
      " -0.07305311  0.10086991 -0.04152989  0.12455638  0.17872035 -0.10852388\n",
      " -0.14837372  0.11572336  0.02301886  0.01532026 -0.12171459  0.14419802\n",
      "  0.05310431 -0.05999232 -0.10839725 -0.0683387  -0.19629519 -0.05491863\n",
      "  0.05611045]\n",
      "[ 0.01367628  0.00139449  0.13491718  0.09457714 -0.059817   -0.01829422\n",
      " -0.08646131 -0.0746911  -0.034578    0.01295665  0.09150355  0.07789917\n",
      "  0.05482252  0.04983432 -0.20710944  0.41116817  0.63906946 -0.27418396\n",
      "  0.54340567  0.04790307  0.60221209  0.23499359  0.22796193  0.0704502\n",
      " -0.01267604]\n"
     ]
    }
   ],
   "source": [
    "print(X_title[1])\n",
    "print(X_title[2])\n",
    "print(X_title[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p3gC4DT8p8oD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.50105998e-03  4.82660145e-03  1.54851480e-02 -2.08299594e-03\n",
      "  2.10600640e-02  3.33919034e-02  1.16616775e-02 -1.97557543e-02\n",
      "  6.05252434e-02 -1.85533649e-02 -3.03902748e-03  1.51005380e-02\n",
      "  3.72283906e-02 -4.00542709e-02  8.81619828e-03  2.47095746e-02\n",
      "  1.16539437e-01 -1.61944706e-01 -1.61709959e-03  1.08077491e-01\n",
      "  1.64607443e-01 -1.20425361e-02  5.41704870e-02  1.00521625e-01\n",
      "  2.86954119e-01  4.51147998e+00 -1.29434808e+00  6.37701376e-01\n",
      "  5.83961304e-01  1.13637386e+00  3.27164379e-02  8.34578941e-01\n",
      " -6.16759271e-01  1.12100501e+00  1.73954512e+00  2.43983389e+00\n",
      "  3.18791078e-01 -1.03826817e-01  3.28381294e-01 -1.31900516e+00\n",
      "  4.69298177e-01 -2.46950411e+00  2.87603650e+00  1.41201555e+00\n",
      " -2.19506678e-01 -4.13767634e-01  5.94269568e-02 -3.94773092e-01\n",
      " -3.37417858e+00  1.45640904e+00  8.28186348e-01 -2.28096903e-01\n",
      "  5.03731181e-01  1.57532242e+00  1.75949451e+00  2.91130564e+00\n",
      " -8.35250121e-01  1.74727724e+00 -2.49133409e-01 -2.07547839e+00\n",
      "  1.67932811e+00  1.39595238e+00  1.27356202e+00  1.41751695e+00\n",
      "  1.05727516e+00 -1.79509353e+00 -1.41167087e+00 -6.91732586e-01\n",
      "  2.66535951e+00 -8.99381578e-01 -3.63679778e-01  2.65136026e-02\n",
      " -5.35750915e-01 -1.09250888e+00  9.29062065e-01  1.18558046e-01\n",
      "  1.79890724e-01 -6.37339642e-02  4.60800020e-01  6.82081684e-02\n",
      " -5.90194761e-05  1.63332637e-01 -5.91156802e-01  8.96261257e-01\n",
      "  7.82626063e-04 -7.38480554e-02 -7.35755557e-02 -6.16189466e-01\n",
      "  1.70017765e-01 -7.29839012e-03  2.26610384e-01 -1.83715033e-01\n",
      "  2.41192653e-02 -1.86710920e-01 -3.64401427e-02 -2.20163045e-02\n",
      "  2.39458133e-01 -6.43748972e-02  9.14967520e-02  2.18965727e-02]\n"
     ]
    }
   ],
   "source": [
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-j7QZidgp8oH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.22569216, 0.13888169, ..., 0.25168722, 0.19693998,\n",
       "        0.14513481],\n",
       "       [0.22569216, 1.        , 0.08326281, ..., 0.13502591, 0.10119108,\n",
       "        0.18047548],\n",
       "       [0.13888169, 0.08326281, 1.        , ..., 0.19780689, 0.21355849,\n",
       "        0.26537198],\n",
       "       ...,\n",
       "       [0.25168722, 0.13502591, 0.19780689, ..., 1.        , 0.13482035,\n",
       "        0.15761966],\n",
       "       [0.19693998, 0.10119108, 0.21355849, ..., 0.13482035, 1.        ,\n",
       "        0.51400967],\n",
       "       [0.14513481, 0.18047548, 0.26537198, ..., 0.15761966, 0.51400967,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = cosine_similarity(X)\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 16],\n",
       " [1],\n",
       " [2],\n",
       " [3, 4, 15, 70, 72, 79, 129],\n",
       " [3, 4, 23, 25, 43, 55, 67, 92],\n",
       " [5, 25, 53, 70, 85, 95, 122, 128, 129],\n",
       " [6, 12, 73, 93, 118],\n",
       " [7, 129],\n",
       " [8],\n",
       " [9],\n",
       " [10],\n",
       " [11],\n",
       " [6, 12, 93],\n",
       " [13, 61, 67, 120, 129],\n",
       " [14, 83],\n",
       " [3, 15, 38, 70],\n",
       " [0, 16, 35],\n",
       " [17, 37, 39, 124, 127],\n",
       " [18, 109, 121],\n",
       " [19, 32, 61],\n",
       " [20, 48, 104, 119, 125],\n",
       " [21],\n",
       " [22],\n",
       " [4, 23, 43, 94],\n",
       " [24, 96, 102],\n",
       " [4, 5, 25, 43, 70, 85, 128],\n",
       " [26],\n",
       " [27],\n",
       " [28, 58, 69, 79, 88],\n",
       " [29, 57, 60, 118],\n",
       " [30, 52, 56, 67],\n",
       " [31],\n",
       " [19, 32, 87, 125],\n",
       " [33],\n",
       " [34, 44],\n",
       " [16, 35],\n",
       " [36, 40],\n",
       " [17, 37, 39, 88, 124],\n",
       " [15, 38],\n",
       " [17, 37, 39, 56],\n",
       " [36, 40, 88],\n",
       " [41],\n",
       " [42, 71, 76, 100],\n",
       " [4, 23, 25, 43],\n",
       " [34, 44, 109],\n",
       " [45, 56, 61, 78, 90, 104],\n",
       " [46],\n",
       " [47],\n",
       " [20, 48, 90, 104, 119, 120],\n",
       " [49],\n",
       " [50],\n",
       " [51],\n",
       " [30, 52, 120],\n",
       " [5, 53, 68, 108, 122, 123, 129],\n",
       " [54],\n",
       " [4, 55],\n",
       " [30, 39, 45, 56],\n",
       " [29, 57, 60, 118],\n",
       " [28, 58],\n",
       " [59],\n",
       " [29, 57, 60, 95, 118],\n",
       " [13, 19, 45, 61, 67, 90, 104, 119, 120, 125],\n",
       " [62],\n",
       " [63, 74],\n",
       " [64, 99, 101],\n",
       " [65],\n",
       " [66],\n",
       " [4, 13, 30, 61, 67, 77, 119, 120, 122, 123, 128],\n",
       " [53, 68, 92, 123],\n",
       " [28, 69],\n",
       " [3, 5, 15, 25, 70, 85, 95],\n",
       " [42, 71, 76],\n",
       " [3, 72, 121],\n",
       " [6, 73, 90],\n",
       " [63, 74],\n",
       " [75],\n",
       " [42, 71, 76],\n",
       " [67, 77],\n",
       " [45, 78],\n",
       " [3, 28, 79, 82],\n",
       " [80],\n",
       " [81],\n",
       " [79, 82],\n",
       " [14, 83],\n",
       " [84],\n",
       " [5, 25, 70, 85],\n",
       " [86],\n",
       " [32, 87, 88, 102],\n",
       " [28, 37, 40, 87, 88, 109],\n",
       " [89],\n",
       " [45, 48, 61, 73, 90, 104, 119, 120],\n",
       " [91],\n",
       " [4, 68, 92, 121, 122, 123],\n",
       " [6, 12, 93],\n",
       " [23, 94, 103],\n",
       " [5, 60, 70, 95, 118, 128],\n",
       " [24, 96, 103, 111],\n",
       " [97],\n",
       " [98],\n",
       " [64, 99],\n",
       " [42, 100],\n",
       " [64, 101],\n",
       " [24, 87, 102],\n",
       " [94, 96, 103, 111],\n",
       " [20, 45, 48, 61, 90, 104, 119, 120, 125],\n",
       " [105, 107],\n",
       " [106],\n",
       " [105, 107],\n",
       " [53, 108],\n",
       " [18, 44, 88, 109],\n",
       " [110],\n",
       " [96, 103, 111],\n",
       " [112, 126],\n",
       " [113],\n",
       " [114],\n",
       " [115, 118],\n",
       " [116],\n",
       " [117],\n",
       " [6, 29, 57, 60, 95, 115, 118, 128],\n",
       " [20, 48, 61, 67, 90, 104, 119, 120],\n",
       " [13, 48, 52, 61, 67, 90, 104, 119, 120],\n",
       " [18, 72, 92, 121],\n",
       " [5, 53, 67, 92, 122, 123, 128, 129],\n",
       " [53, 67, 68, 92, 122, 123, 129],\n",
       " [17, 37, 124],\n",
       " [20, 32, 61, 104, 125],\n",
       " [112, 126],\n",
       " [17, 127],\n",
       " [5, 25, 67, 95, 118, 122, 128, 129],\n",
       " [3, 5, 7, 13, 53, 122, 123, 128, 129]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_doc = []\n",
    "docx = 0\n",
    "docy = 0\n",
    "temp_sim = []\n",
    "\n",
    "for x in sim:\n",
    "    for y in x:\n",
    "        if y > 0.5:\n",
    "            temp_sim.append(docy)\n",
    "        docy = docy+1\n",
    "    \n",
    "    sim_doc.append(temp_sim)\n",
    "    docy = 0\n",
    "    temp_sim = []\n",
    "            \n",
    "            \n",
    "sim_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
